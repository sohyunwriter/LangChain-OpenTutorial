{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGVector\n",
    "\n",
    "- Author: [Min-su Jung](https://github.com/effort-type), [Joonha Jeon](https://github.com/realjoonha), [Jongho Lee](https://github.com/XaviereKU)\n",
    "- Design: \n",
    "- Peer Review : \n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/09-VectorStore/07-PGVector.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/09-VectorStore/07-PGVector.ipynb)\n",
    "\n",
    "## Overview  \n",
    "\n",
    "[```PGVector```](https://github.com/pgvector/pgvector) is an open-source extension for PostgreSQL that allows you to store and search vector data alongside your regular database information.\n",
    "\n",
    "This notebook shows how to use functionality related to ```PGVector```, implementing LangChain vectorstore abstraction using postgres as the backend and utilizing the pgvector extension.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [What is PGVector?](#what-is-pgvector)\n",
    "- [Initialization](#initialization)\n",
    "- [Manage vector store](#manage-vector-store)\n",
    "- [Similarity search](#similarity-search)\n",
    "\n",
    "### References\n",
    "\n",
    "- [langchain-postgres](https://github.com/langchain-ai/langchain-postgres/)\n",
    "- [pgvector](https://github.com/pgvector/pgvector)\n",
    "- [Docker Desktop for Windows](https://docs.docker.com/desktop/setup/install/windows-install)\n",
    "- [Docker Desktop for Mac](https://docs.docker.com/desktop/setup/install/mac-install/)\n",
    "- [Install pgvector on Windows](https://dev.to/mehmetakar/install-pgvector-on-windows-6gl)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_openai\",\n",
    "        \"pgvector\",\n",
    "        \"psycopg\",\n",
    "        \"psycopg-binary\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"PGVector\",\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is PGVector?\n",
    "\n",
    "`PGVector` is a ```PostgreSQL``` extension that enables vector similarity search directly within your ```PostgreSQL``` database, making it ideal for AI applications, semantic search, and recommendation systems.\n",
    "\n",
    "This is particularly valuable for who already use ```PostgreSQL``` who want to add vector search capabilities without managing separate infrastructure or learning new query languages.\n",
    "\n",
    "**Features** :\n",
    "1. Native ```PostgreSQL``` integration with standard SQL queries\n",
    "2. Multiple similarity search methods including L2, Inner Product, Cosine\n",
    "3. Several indexing options including HNSW and IVFFlat\n",
    "4. Support for up to 2,000 dimensions per vector\n",
    "5. ACID compliance inherited from ```PostgreSQL```\n",
    "\n",
    "**Advantages** :\n",
    "\n",
    "1. Free and open-source\n",
    "2. Easy integration with existing ```PostgreSQL``` databases\n",
    "3. Full SQL functionality and transactional support\n",
    "4. No additional infrastructure needed\n",
    "5. Supports hybrid searches combining vector and traditional SQL queries\n",
    "\n",
    "**Disadvantages** :\n",
    "1. Performance limitations with very large datasets (billions of vectors)\n",
    "2. Limited to single-node deployment\n",
    "3. Memory-intensive for large vector dimensions\n",
    "4. Requires manual optimization for best performance\n",
    "5. Less specialized features compared to dedicated vector databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up PGVector\n",
    "\n",
    "If you are using Windows and have installed postgresql for Windows, you are required to install **vector** extension for postgresql. The following may help [Install pgvector on Windows](https://dev.to/mehmetakar/install-pgvector-on-windows-6gl).\n",
    "\n",
    "But in this tutorial, we will use ```Docker``` container. If you are using Mac or Windows, check [Docker Desktop for Mac](https://docs.docker.com/desktop/setup/install/mac-install/) or [Docker Desktop for Windows](https://docs.docker.com/desktop/setup/install/windows-install).\n",
    "\n",
    "If you are using ```Docker``` desktop, you can easily set up `PGVector` by running the following command that spins up a ```Docker``` container:\n",
    "\n",
    "```bash\n",
    "docker run --name pgvector-container -e POSTGRES_USER=langchain -e POSTGRES_PASSWORD=langchain -e POSTGRES_DB=langchain -p 6024:5432 -d pgvector/pgvector:pg16\n",
    "```\n",
    "\n",
    "For more detailed instructions, please refer to [the official documentation](https://github.com/pgvector/pgvector) \n",
    "\n",
    "** [ NOTE ] **\n",
    "* If you want to maintain the stored data even after container being deleted, you must mount volume like below:\n",
    "```bash\n",
    "docker run --name pgvector-container -v {/mount/path}:/var/lib/postgresql/data -e POSTGRES_USER=langchain -e POSTGRES_PASSWORD=langchain -e POSTGRES_DB=langchain -p 6024:5432 -d pgvector/pgvector:pg16\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "If you are successfully running the pgvector container, you can use ```pgVectorIndexManager``` from ```pgvector_interface``` in utils directory to handle collections.\n",
    "\n",
    "To initialize ```pgVectorIndexManager``` you can pass full connection string or pass each parameter separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pgvector_interface import pgVectorIndexManager\n",
    "\n",
    "# Setup connection infomation\n",
    "conn_str = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    "\n",
    "# Initialize pgVectorIndexManaer\n",
    "index_manager = pgVectorIndexManager(connection=conn_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you initialize ```pgVectorIndexManager```, the procedure will automatically create two tables\n",
    "**langchain_pg_collection** and **langchain_pg_embedding.**\n",
    "\n",
    "* langchain_pg_collection\n",
    "    * Stores **names** of the collections.\n",
    "    * Distinguish collection by uuid and name.\n",
    "* langchain_pg_embedding\n",
    "    * Stores actual data.\n",
    "    \n",
    "So, when you create a new collection and insert data to the collection, the data will be stored in **langchain_pg_embedding** table.\n",
    "\n",
    "As you can see below, the uuid column in langchain_pg_collection table matched with collection_id column in langchain_pg_embedding table.\n",
    "\n",
    "![pgVector Entity Relation](./assets/08-pgvector-entityRelation.png)\n",
    "\n",
    "\n",
    "![pgVector Collection](./assets/08-pgvector-collection.png)\n",
    "\n",
    "\n",
    "![pgVector Data](./assets/08-pgvector-data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create collection\n",
    "Now we can create collection with ```index_manager```.\n",
    "\n",
    "To create collection, you need to pass **embedding** model and **collection_name** when calling the ```create_index``` method.\n",
    "\n",
    "In this tutorial we will use ```text-embedding-3-large``` model of OpenAI.\n",
    "\n",
    "If creation is successful, the method will return ```pgVectorDocumentManager``` class that can handle actual data.\n",
    "\n",
    "In this tutorial we will create an collection with name **langchain_opentutorial.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new collection\n",
    "col_manager = index_manager.create_index(\n",
    "    collection_name=\"langchain_opentutorial\", embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List collections\n",
    "\n",
    "As we have created a new collection, we will call the ```list_indexes``` method to check if the collection is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['langchain_opentutorial']\n"
     ]
    }
   ],
   "source": [
    "# check collections\n",
    "indexes = index_manager.list_indexes()\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete collections\n",
    "\n",
    "We can also delete collection by calling the ```delete_index``` method by pass the name of the collection to delete.\n",
    "\n",
    "We delete **langchain_opentutorial** collection, and then create it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# delete collection\n",
    "index_manager.delete_index(\"langchain_opentutorial\")\n",
    "\n",
    "# check collections\n",
    "indexes = index_manager.list_indexes()\n",
    "print(indexes)\n",
    "\n",
    "# Create again\n",
    "col_manager_tmp1 = index_manager.create_index(\n",
    "    collection_name=\"langchain_opentutorial\", embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get collection\n",
    "As we said, when you create a new collection by calling the ```create_index``` method, this will automatically return ```pgVectorDocumentManager``` instance.\n",
    "\n",
    "But if you want to re-use already created collection, you can call the ```get_index``` method with name of the collection and embedding model you used to create the collection to get manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get collection\n",
    "col_manager_tmp2 = index_manager.get_index(\n",
    "    embedding=embeddings, collection_name=\"langchain_opentutorial\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage vector store\n",
    "\n",
    "Once you have created your vector store, we can interact with it by adding and deleting different items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "The ```pgVector``` support following filtering operations.\n",
    "\n",
    "| Operator | Meaning/Category        |\n",
    "|----------|-------------------------|\n",
    "| \\$eq      | Equality (==)           |\n",
    "| \\$ne      | Inequality (!=)         |\n",
    "| \\$lt      | Less than (&lt;)           |\n",
    "| \\$lte     | Less than or equal (&lt;=) |\n",
    "| \\$gt      | Greater than (>)        |\n",
    "| \\$gte     | Greater than or equal (>=) |\n",
    "| \\$in      | Special Cased (in)      |\n",
    "| \\$nin     | Special Cased (not in)  |\n",
    "| \\$between | Special Cased (between) |\n",
    "| \\$like    | Text (like)             |\n",
    "| \\$ilike   | Text (case-insensitive like) |\n",
    "| \\$and     | Logical (and)           |\n",
    "| \\$or      | Logical (or)            |\n",
    "\n",
    "Filter can be used with ```scroll```, ```delete```, and ```search``` methods.\n",
    "\n",
    "To apply filter, we create a dictionary and pass it to ```filter``` parameter like the following\n",
    "```python\n",
    "{\"page\": {\"$between\": [10,20]}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to index\n",
    "To add, delete, search items, we need to initialize an object which connected to the index we operate on.\n",
    "\n",
    "We will connect to **langchain_opentutorial** . Recall that we used basic ```OpenAIEmbedding``` as a embedding function, and thus we need to pass it when we initialize ```index_manager``` object.\n",
    "\n",
    "Remember that we also can get ```pgVectorDocumentManager``` object when we create an index with ```pgVectorIndexManager``` object or ```pgVectorIndexManager.get_index``` method, but this time we call it directly to get an ```pgVectorDocumentManager``` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pgvector_interface import pgVectorDocumentManager\n",
    "\n",
    "# Get document manager\n",
    "col_manager = pgVectorDocumentManager(\n",
    "    embedding=embeddings,\n",
    "    connection_info=conn_str,\n",
    "    collection_name=\"langchain_opentutorial\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Below is the preprocessing process for general documents.\n",
    "\n",
    "- Need to extract **metadata** from documents\n",
    "- Filter documents by minimum length.\n",
    "  \n",
    "- Determine whether to use ```basename``` or not. Default is ```False```.\n",
    "  - ```basename``` denotes the last value of the filepath.\n",
    "  - For example, **document.pdf** will be the ```basename``` for the filepath **./data/document.pdf** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a long document we can split up.\n",
    "data_path = \"./data/the_little_prince.txt\"\n",
    "with open(data_path, encoding=\"utf8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='The Little Prince\n",
      "Written By Antoine de Saiot-Exupery (1900〜1944)'\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from uuid import uuid4\n",
    "\n",
    "# define text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "# split raw text by splitter.\n",
    "split_docs = text_splitter.create_documents([raw_text])\n",
    "\n",
    "# print one of documents to check its structure\n",
    "print(split_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define document preprocessor\n",
    "def preprocess_documents(\n",
    "    split_docs, metadata_keys, min_length, use_basename=False, **kwargs\n",
    "):\n",
    "    metadata = kwargs\n",
    "\n",
    "    if use_basename:\n",
    "        assert metadata.get(\"source\", None) is not None, \"source must be provided\"\n",
    "        metadata[\"source\"] = metadata[\"source\"].split(\"/\")[-1]\n",
    "\n",
    "    result_docs = []\n",
    "    for idx, doc in enumerate(split_docs):\n",
    "        if len(doc.page_content) < min_length:\n",
    "            continue\n",
    "        for k in metadata_keys:\n",
    "            doc.metadata.update({k: metadata.get(k, \"\")})\n",
    "        doc.metadata.update({\"page\": idx + 1, \"id\": str(uuid4())})\n",
    "        result_docs.append(doc)\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='The Little Prince\n",
      "Written By Antoine de Saiot-Exupery (1900〜1944)' metadata={'source': 'the_little_prince.txt', 'page': 1, 'author': 'Saiot-Exupery', 'id': 'cc23e228-2540-4e5c-8eb3-be6df7a3bf77'}\n"
     ]
    }
   ],
   "source": [
    "# preprocess raw documents\n",
    "processed_docs = preprocess_documents(\n",
    "    split_docs=split_docs,\n",
    "    metadata_keys=[\"source\", \"page\", \"author\"],\n",
    "    min_length=5,\n",
    "    use_basename=True,\n",
    "    source=data_path,\n",
    "    author=\"Saiot-Exupery\",\n",
    ")\n",
    "\n",
    "# print one of preprocessed document to chekc its structure\n",
    "print(processed_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add items to vector store\n",
    "\n",
    "We can add items to our vector store by using the ```upsert``` or ```upsert_parallel``` method.\n",
    "\n",
    "If you pass ids along with documents, then ids will be used, but if you do not pass ids, it will be created based `page_content` using md5 hash function.\n",
    "\n",
    "Basically, ```upsert``` and ```upsert_parallel``` methods do upsert not insert, based on **id** of the item.\n",
    "\n",
    "So if you provided id and want to update data, you must provide the same id that you provided at first upsertion.\n",
    "\n",
    "We will upsert data to collection, **langchain_opentutorial** , with ```upsert``` method for the first half, and with ```upsert_parallel``` for the second half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1359\n"
     ]
    }
   ],
   "source": [
    "# Gather uuids, texts, metadatas\n",
    "uuids = [doc.metadata[\"id\"] for doc in processed_docs]\n",
    "texts = [doc.page_content for doc in processed_docs]\n",
    "metadatas = [doc.metadata for doc in processed_docs]\n",
    "\n",
    "# Get total number of documents\n",
    "total_number = len(processed_docs)\n",
    "print(\"Number of documents:\", total_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.57 s, sys: 140 ms, total: 1.71 s\n",
      "Wall time: 5.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# upsert documents\n",
    "upsert_result = col_manager.upsert(\n",
    "    \n",
    "    texts=texts[:total_number//2], metadatas=metadatas[:total_number//2], ids=uuids[:total_number//2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.79 s, sys: 82.9 ms, total: 1.88 s\n",
      "Wall time: 4.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# upsert documents parallel\n",
    "upsert_parallel_result = col_manager.upsert_parallel(\n",
    "    texts = texts[total_number//2 :],\n",
    "    metadatas = metadatas[total_number//2:],\n",
    "    ids = uuids[total_number//2:],\n",
    "    batch_size=32,\n",
    "    max_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1359\n",
      "Manual Ids == Output Ids: True\n"
     ]
    }
   ],
   "source": [
    "result = upsert_result + upsert_parallel_result\n",
    "\n",
    "# check number of ids upserted\n",
    "print(len(result))\n",
    "\n",
    "# check manual ids are the same as output ids\n",
    "print(\"Manual Ids == Output Ids:\", sorted(result) == sorted(uuids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ NOTE ]**\n",
    "\n",
    "As we have only one table, **langchain_pg_embedding** to store data, we have only one column **cmetadata** to store metadata for each document.\n",
    "\n",
    "The **cmetadata** column is jsonb type, and thus if you want to update the metadata, you should provide not only the new metadata key-value you want to update, but with all the metadata already stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scroll items from vector store\n",
    "As we have added some items to our first vector store, named **langchain_opentutorial** , we can scroll items from the vector store.\n",
    "\n",
    "This can be done by calling ```scroll``` method.\n",
    "\n",
    "When we scroll items from the vector store we can pass ```ids``` or ```filter``` to get items that we want, or just call ```scroll``` to get ```k```(*default 10*) items.\n",
    "\n",
    "We can get embedded vector values of each items by set ```include_embedding``` True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items scrolled: 10\n",
      "{'content': 'The Little Prince\\nWritten By Antoine de Saiot-Exupery (1900〜1944)', 'metadata': {'id': 'cc23e228-2540-4e5c-8eb3-be6df7a3bf77', 'page': 1, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None}\n"
     ]
    }
   ],
   "source": [
    "# Do scroll without ids or filter\n",
    "scroll_result = col_manager.scroll()\n",
    "\n",
    "# print the number of items scrolled and first item that returned.\n",
    "print(f\"Number of items scrolled: {len(scroll_result)}\")\n",
    "print(scroll_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items scrolled: 3\n",
      "{'content': 'The Little Prince\\nWritten By Antoine de Saiot-Exupery (1900〜1944)', 'metadata': {'id': 'cc23e228-2540-4e5c-8eb3-be6df7a3bf77', 'page': 1, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None}\n",
      "{'content': '[ Antoine de Saiot-Exupery ]', 'metadata': {'id': 'd4bf8981-2af4-4288-8aaf-6586381973c4', 'page': 2, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None}\n",
      "{'content': 'Over the past century, the thrill of flying has inspired some to perform remarkable feats of', 'metadata': {'id': '31dc52cf-530b-449c-a3db-ec64d9e1a10c', 'page': 3, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None}\n"
     ]
    }
   ],
   "source": [
    "# Do scroll with filter\n",
    "scroll_result = col_manager.scroll(filter={\"page\": {\"$in\": [1, 2, 3]}})\n",
    "\n",
    "# print the number of items scrolled and all items that returned.\n",
    "print(f\"Number of items scrolled: {len(scroll_result)}\")\n",
    "for r in scroll_result:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items scrolled: 3\n",
      "{'content': 'The Little Prince\\nWritten By Antoine de Saiot-Exupery (1900〜1944)', 'metadata': {'id': 'cc23e228-2540-4e5c-8eb3-be6df7a3bf77', 'page': 1, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None}\n",
      "{'content': '[ Antoine de Saiot-Exupery ]', 'metadata': {'id': 'd4bf8981-2af4-4288-8aaf-6586381973c4', 'page': 2, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None}\n",
      "{'content': 'Over the past century, the thrill of flying has inspired some to perform remarkable feats of', 'metadata': {'id': '31dc52cf-530b-449c-a3db-ec64d9e1a10c', 'page': 3, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None}\n"
     ]
    }
   ],
   "source": [
    "# Do scroll with ids\n",
    "scroll_result = col_manager.scroll(ids=uuids[:3])\n",
    "\n",
    "# print the number of items scrolled and all items that returned.\n",
    "print(f\"Number of items scrolled: {len(scroll_result)}\")\n",
    "for r in scroll_result:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete items from vector store\n",
    "\n",
    "We can delete items by filter or ids with ```delete``` method.\n",
    "\n",
    "\n",
    "For example, we will delete **the first page**, that is ```page``` 1, of the little prince, and try to scroll it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete done successfully\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# delete an item\n",
    "col_manager.delete(filter={\"page\": {\"$eq\": 1}})\n",
    "\n",
    "# check if it remains in DB.\n",
    "print(col_manager.scroll(filter={\"page\": {\"$eq\": 1}}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we delete 5 items using ```ids```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete done successfully\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# delete item by ids\n",
    "ids = uuids[1:6]\n",
    "\n",
    "# call delete_node method\n",
    "col_manager.delete(ids=ids)\n",
    "\n",
    "# check if it remains in DB.\n",
    "print(col_manager.scroll(ids=ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity search\n",
    "\n",
    "As a vector store, ```pgVector``` support similarity search with various distance metric, **l2** , **inner** (max inner product), **cosine** .\n",
    "\n",
    "By default, distance strategy is set to **cosine.** \n",
    "\n",
    "Similarity search can be done by calling the ```search``` method.\n",
    "\n",
    "You can set the number of retrieved documents by passing ```k```(*default to 4*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '\"My friend the fox--\" the little prince said to me.', 'metadata': {'id': 'b02aaaa0-9352-403a-8924-cfff4973b926', 'page': 1087, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None, 'score': 0.631413271508214}\n",
      "{'content': '\"No,\" said the little prince. \"I am looking for friends. What does that mean-- ‘tame‘?\"', 'metadata': {'id': '48adae15-36ba-4384-8762-0ef3f0ac33a3', 'page': 958, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None, 'score': 0.6050397117589812}\n",
      "{'content': 'the little prince returns to his planet', 'metadata': {'id': '4ed37f54-5619-4fc9-912b-4a37fb5a5625', 'page': 1202, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None, 'score': 0.5846221199406966}\n",
      "{'content': 'midst of the Sahara where he meets a tiny prince from another world traveling the universe in order', 'metadata': {'id': '28b44d4b-cf4e-4cb9-983b-7fb3ec735609', 'page': 25, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None, 'score': 0.5682375512406654}\n",
      "{'content': '[ Chapter 2 ]\\n- the narrator crashes in the desert and makes the acquaintance of the little prince', 'metadata': {'id': '2a4e0184-bc2c-4558-8eaa-63a1a13da3a0', 'page': 85, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None, 'score': 0.555493427632688}\n"
     ]
    }
   ],
   "source": [
    "results = col_manager.search(query=\"Does the little prince have a friend?\", k=5)\n",
    "for doc in results:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity search with filters\n",
    "\n",
    "You can also do similarity search with filter as we have done in ```scroll``` or ```delete```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'inhabited region. And yet my little man seemed neither to be straying uncertainly among the sands,', 'metadata': {'id': '1be69712-f0f4-4728-b6f2-d4cf12cddfdb', 'page': 107, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None, 'score': 0.23158187113240447}\n",
      "{'content': 'Nothing about him gave any suggestion of a child lost in the middle of the desert, a thousand miles', 'metadata': {'id': 'df4ece8c-dcb6-400e-9d8e-0eb5820a5c4e', 'page': 109, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None, 'score': 0.18018012822748797}\n",
      "{'content': 'among the sands, nor to be fainting from fatigue or hunger or thirst or fear. Nothing about him', 'metadata': {'id': '71b4297c-3b76-43cb-be6a-afca5f59388d', 'page': 108, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None, 'score': 0.17715921622781305}\n",
      "{'content': 'less charming than its model.', 'metadata': {'id': '507267bc-7076-42f7-ad7c-ed1f835663f2', 'page': 100, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None, 'score': 0.16131896837723747}\n",
      "{'content': 'a thousand miles from any human habitation. When at last I was able to speak, I said to him:', 'metadata': {'id': '524af6ff-1370-4c20-ad94-1b37e45fe0c5', 'page': 110, 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt'}, 'embedding': None, 'score': 0.15769872390077566}\n"
     ]
    }
   ],
   "source": [
    "# search with filter\n",
    "result_with_filter = col_manager.search(\n",
    "    \"Does the little prince have a friend?\",\n",
    "    filter={\"page\": {\"$between\": [100, 110]}},\n",
    "    k=5,\n",
    ")\n",
    "\n",
    "for doc in result_with_filter:\n",
    "    print(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testbed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
